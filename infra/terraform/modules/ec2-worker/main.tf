# KMS í‚¤ ìƒíƒœ ê²€ì¦ì„ ìœ„í•œ ë°ì´í„° ì†ŒìŠ¤ ì¶”ê°€
data "aws_kms_key" "validate_key" {
  count  = var.kms_key_id != "" ? 1 : 0
  key_id = var.kms_key_id
}

# KMS í‚¤ ì¤€ë¹„ í™•ì¸ì„ ìœ„í•œ null_resource
resource "null_resource" "wait_for_kms" {
  count = var.kms_key_id != "" ? 1 : 0
  
  provisioner "local-exec" {
    command = <<-EOT
      echo "ğŸ” Workerìš© KMS í‚¤ ìƒíƒœ ê²€ì¦ ì¤‘..."
      for i in {1..30}; do
        STATE=$(aws kms describe-key --key-id ${var.kms_key_id} --region ${var.aws_region} --query 'KeyMetadata.KeyState' --output text 2>/dev/null || echo "ERROR")
        echo "ì‹œë„ $i/30: KMS í‚¤ ìƒíƒœ = $STATE"
        if [ "$STATE" = "Enabled" ]; then
          echo "âœ… KMS í‚¤ê°€ Worker EC2 ì‚¬ìš© ì¤€ë¹„ ì™„ë£Œ"
          sleep 5  # ì¶”ê°€ ì•ˆì •í™” ëŒ€ê¸°
          exit 0
        fi
        echo "â³ KMS í‚¤ ì¤€ë¹„ ì¤‘... (10ì´ˆ í›„ ì¬ì‹œë„)"
        sleep 10
      done
      echo "âŒ KMS í‚¤ ì¤€ë¹„ ì‹œê°„ ì´ˆê³¼"
      exit 1
    EOT
  }

  depends_on = [data.aws_kms_key.validate_key]
}

resource "aws_instance" "worker" {
  count         = var.worker_count
  ami           = var.ami_id
  instance_type = var.instance_type
  subnet_id     = var.subnet_id
  key_name      = var.ssh_key_name != null ? var.ssh_key_name : null

  vpc_security_group_ids = [aws_security_group.worker.id]

  root_block_device {
    volume_size = var.root_volume_size
    volume_type = "gp3"
    encrypted   = var.kms_key_id != "" ? true : false
    kms_key_id  = var.kms_key_id != "" ? var.kms_key_id : null
  }

  user_data = base64encode(templatefile("${path.module}/templates/worker_user_data.sh", {
    master_private_ip = var.master_private_ip
    node_index        = count.index + 1
  }))

  tags = merge(var.tags, {
    Name = "${var.project_name}-worker-${count.index + 1}"
    Role = "worker"
  })

  # KMS í‚¤ê°€ ì™„ì „íˆ ì¤€ë¹„ëœ í›„ì— ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
  depends_on = [null_resource.wait_for_kms]
}

resource "aws_security_group" "worker" {
  name        = "${var.project_name}-worker"
  description = "Security group for Kubernetes worker nodes"
  vpc_id      = var.vpc_id

  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
    description = "SSH"
  }

  # Master Security Groupì—ì„œì˜ íŠ¸ë˜í”½ì€ ë³„ë„ ê·œì¹™ìœ¼ë¡œ ê´€ë¦¬

  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }

  tags = merge(var.tags, {
    Name = "${var.project_name}-worker-sg"
  })
}

# Master ë…¸ë“œì—ì„œ Worker ë…¸ë“œë¡œì˜ ëª¨ë“  íŠ¸ë˜í”½ í—ˆìš©
resource "aws_security_group_rule" "worker_ingress_from_master" {
  count                    = var.master_security_group_id != "" ? 1 : 0
  type                     = "ingress"
  from_port                = 0
  to_port                  = 0
  protocol                 = "-1"
  security_group_id        = aws_security_group.worker.id
  source_security_group_id = var.master_security_group_id
  description              = "All traffic from master node"
  
  depends_on = [aws_security_group.worker]
} 