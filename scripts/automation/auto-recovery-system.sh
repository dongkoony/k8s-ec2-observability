#!/bin/bash

#############################################
# Auto Recovery System for k8s-ec2-observability
# Step 8: Real-world Observability Implementation
#############################################

set -euo pipefail

# ì„¤ì • ë³€ìˆ˜
MASTER_NODE="ip-10-0-1-34"
LOG_FILE="/tmp/auto-recovery.log"
CHECK_INTERVAL=30

# ë¡œê¹… í•¨ìˆ˜
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_FILE}"
}

# ë§ˆìŠ¤í„° ë…¸ë“œë¡œ ê°•ì œ ì´ë™ í•¨ìˆ˜
force_to_master() {
    local namespace=$1
    local deployment=$2
    
    log "ğŸ”„ Moving ${deployment} in ${namespace} to master node..."
    
    kubectl patch deployment "${deployment}" -n "${namespace}" -p "{
        \"spec\": {
            \"template\": {
                \"spec\": {
                    \"nodeSelector\": {
                        \"kubernetes.io/hostname\": \"${MASTER_NODE}\"
                    },
                    \"tolerations\": [
                        {
                            \"key\": \"node-role.kubernetes.io/control-plane\",
                            \"operator\": \"Exists\",
                            \"effect\": \"NoSchedule\"
                        }
                    ]
                }
            }
        }
    }" 2>/dev/null || log "âš ï¸  Failed to patch ${deployment}"
}

# 1. OOMKilled Pod ìë™ ë³µêµ¬
check_oomkilled_pods() {
    log "ğŸ” Checking for OOMKilled pods..."
    
    local oomkilled_pods
    oomkilled_pods=$(kubectl get pods -A -o json | jq -r '
        .items[] | 
        select(.status.containerStatuses[]?.lastState.terminated.reason == "OOMKilled") |
        "\(.metadata.namespace)/\(.metadata.name)"
    ' 2>/dev/null || echo "")
    
    if [[ -n "${oomkilled_pods}" ]]; then
        log "ğŸš¨ Found OOMKilled pods: ${oomkilled_pods}"
        
        # OOMKilledëœ í¬ë“œë“¤ ì¬ì‹œì‘
        echo "${oomkilled_pods}" | while read -r pod_info; do
            if [[ -n "${pod_info}" ]]; then
                namespace=$(echo "${pod_info}" | cut -d'/' -f1)
                pod_name=$(echo "${pod_info}" | cut -d'/' -f2)
                
                log "â™»ï¸  Restarting OOMKilled pod: ${pod_name} in ${namespace}"
                kubectl delete pod "${pod_name}" -n "${namespace}" 2>/dev/null || true
            fi
        done
    fi
}

# 2. ë¦¬ì†ŒìŠ¤ ë¶€ì¡±ìœ¼ë¡œ Pendingì¸ Pod ì²˜ë¦¬
check_pending_pods() {
    log "ğŸ” Checking for resource-constrained pending pods..."
    
    local pending_pods
    pending_pods=$(kubectl get pods -A -o json | jq -r '
        .items[] | 
        select(.status.phase == "Pending" and .status.conditions[]?.reason == "Unschedulable") |
        "\(.metadata.namespace)/\(.metadata.name)"
    ' 2>/dev/null || echo "")
    
    if [[ -n "${pending_pods}" ]]; then
        log "âš ï¸  Found pending pods due to resource constraints: ${pending_pods}"
        
        # CPU ì‚¬ìš©ëŸ‰ í™•ì¸
        local cpu_usage
        cpu_usage=$(kubectl describe node "${MASTER_NODE}" | grep -A3 "Allocated resources" | grep "cpu" | awk '{print $2}' | sed 's/[()%]//g' || echo "0")
        
        if [[ "${cpu_usage:-0}" -gt 95 ]]; then
            log "ğŸš¨ Master node CPU usage is ${cpu_usage}% - Need resource optimization!"
            
            # ìš°ì„ ìˆœìœ„ê°€ ë‚®ì€ í¬ë“œ ìŠ¤ì¼€ì¼ ë‹¤ìš´ (ì˜ˆ: reviews v2, v3)
            kubectl scale deployment reviews-v2 -n bookinfo --replicas=0 2>/dev/null || true
            kubectl scale deployment reviews-v3 -n bookinfo --replicas=0 2>/dev/null || true
            
            log "ğŸ“‰ Scaled down low-priority deployments to free resources"
        fi
    fi
}

# 3. ì„œë¹„ìŠ¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§ ë° ë³µêµ¬
check_service_health() {
    log "ğŸ” Checking critical service health..."
    
    # Linkerd ìƒíƒœ í™•ì¸
    local linkerd_status
    linkerd_status=$(linkerd check --proxy 2>/dev/null | grep -c "âˆš" || echo "0")
    
    if [[ "${linkerd_status}" -lt 5 ]]; then
        log "ğŸš¨ Linkerd health issues detected, attempting recovery..."
        
        # Linkerd ì»´í¬ë„ŒíŠ¸ ì¬ì‹œì‘
        kubectl rollout restart deployment -n linkerd 2>/dev/null || true
        kubectl rollout restart deployment -n linkerd-viz 2>/dev/null || true
    fi
    
    # Prometheus Stack ìƒíƒœ í™•ì¸
    local failed_pods
    failed_pods=$(kubectl get pods -n monitoring --no-headers | grep -v "Running\|Completed" | wc -l || echo "0")
    
    if [[ "${failed_pods}" -gt 0 ]]; then
        log "ğŸš¨ Found ${failed_pods} failed monitoring pods, restarting..."
        kubectl rollout restart deployment -n monitoring 2>/dev/null || true
    fi
}

# 4. Linkerd í”„ë¡ì‹œ ì£¼ì… ìƒíƒœ í™•ì¸ ë° ë³µêµ¬
check_linkerd_injection() {
    log "ğŸ” Checking Linkerd proxy injection status..."
    
    # bookinfo ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ í¬ë“œ ì¤‘ í”„ë¡ì‹œê°€ ì—†ëŠ” ê²ƒë“¤ í™•ì¸
    local pods_without_proxy
    pods_without_proxy=$(kubectl get pods -n bookinfo -o json | jq -r '
        .items[] | 
        select(.spec.containers | length == 1) |
        .metadata.name
    ' 2>/dev/null || echo "")
    
    if [[ -n "${pods_without_proxy}" ]]; then
        log "ğŸ”„ Found pods without Linkerd proxy, restarting for injection..."
        
        # bookinfo ë„¤ì„ìŠ¤í˜ì´ìŠ¤ annotation ì¬í™•ì¸
        kubectl annotate namespace bookinfo linkerd.io/inject=enabled --overwrite 2>/dev/null || true
        
        # í”„ë¡ì‹œê°€ ì—†ëŠ” í¬ë“œë“¤ ì¬ì‹œì‘
        echo "${pods_without_proxy}" | while read -r pod_name; do
            if [[ -n "${pod_name}" ]]; then
                log "â™»ï¸  Restarting pod for proxy injection: ${pod_name}"
                kubectl delete pod "${pod_name}" -n bookinfo 2>/dev/null || true
            fi
        done
    fi
}

# 5. ë§ˆìŠ¤í„° ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ìµœì í™”
optimize_master_node() {
    log "ğŸ”§ Optimizing master node resource allocation..."
    
    # ëª¨ë“  ì¤‘ìš” ì»´í¬ë„ŒíŠ¸ê°€ ë§ˆìŠ¤í„° ë…¸ë“œì— ìˆëŠ”ì§€ í™•ì¸
    local namespaces=("linkerd" "linkerd-viz" "monitoring" "bookinfo")
    
    for ns in "${namespaces[@]}"; do
        log "ğŸ” Checking deployments in namespace: ${ns}"
        
        local deployments
        deployments=$(kubectl get deployments -n "${ns}" -o name 2>/dev/null | sed 's/deployment.apps\///' || echo "")
        
        echo "${deployments}" | while read -r deployment; do
            if [[ -n "${deployment}" ]]; then
                # í˜„ì¬ ë°°ì¹˜ëœ ë…¸ë“œ í™•ì¸
                local current_node
                current_node=$(kubectl get pods -n "${ns}" -l app="${deployment}" -o json 2>/dev/null | jq -r '.items[0].spec.nodeName // empty' || echo "")
                
                if [[ "${current_node}" != "${MASTER_NODE}" && -n "${current_node}" ]]; then
                    log "ğŸšš Moving ${deployment} from ${current_node} to master node"
                    force_to_master "${ns}" "${deployment}"
                fi
            fi
        done
    done
}

# 6. ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ìˆ˜ì§‘
collect_metrics() {
    log "ğŸ“Š Collecting system metrics..."
    
    # ë…¸ë“œ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰
    kubectl describe node "${MASTER_NODE}" | grep -A5 "Allocated resources" | tee -a "${LOG_FILE}"
    
    # í¬ë“œ ìƒíƒœ ìš”ì•½
    log "ğŸ“‹ Pod Status Summary:"
    kubectl get pods -A --no-headers | awk '{print $4}' | sort | uniq -c | tee -a "${LOG_FILE}"
    
    # Linkerd ìƒíƒœ
    log "ğŸ”— Linkerd Status:"
    linkerd check --proxy 2>/dev/null | tail -5 | tee -a "${LOG_FILE}" || log "Linkerd check failed"
}

# ë©”ì¸ ë³µêµ¬ ë£¨í”„
main_recovery_loop() {
    log "ğŸš€ Starting Auto Recovery System for k8s-ec2-observability"
    log "ğŸ¯ Target: ${MASTER_NODE}"
    log "â° Check interval: ${CHECK_INTERVAL} seconds"
    
    while true; do
        log "ğŸ”„ Starting recovery cycle..."
        
        # ëª¨ë“  ì²´í¬ í•¨ìˆ˜ ì‹¤í–‰
        check_oomkilled_pods
        check_pending_pods
        check_service_health
        check_linkerd_injection
        optimize_master_node
        collect_metrics
        
        log "âœ… Recovery cycle completed. Next check in ${CHECK_INTERVAL} seconds..."
        sleep "${CHECK_INTERVAL}"
    done
}

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
case "${1:-run}" in
    "run")
        main_recovery_loop
        ;;
    "test")
        log "ğŸ§ª Running one-time test cycle..."
        check_oomkilled_pods
        check_pending_pods
        check_service_health
        check_linkerd_injection
        optimize_master_node
        collect_metrics
        log "âœ… Test cycle completed"
        ;;
    *)
        echo "Usage: $0 [run|test]"
        echo "  run  - Start continuous auto recovery (default)"
        echo "  test - Run one-time recovery check"
        exit 1
        ;;
esac 